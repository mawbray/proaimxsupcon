{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max Mowbray, Imperial College London\n",
    "# Contracted by ProAim for Supcon workshops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is a notebook to demonstrate particle swarm optimisation (PSO) to find a solution optimal control policy in a form of derivative free RL.\n",
    "```\n",
    "\n",
    "```\n",
    "# Most of the PSO code was pulled from Tom Savage's Github repository: TomRSavage\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.integrate as scp\n",
    "import copy\n",
    "import numpy.random as rnd\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set point tracking for a dynamic system\n",
    "\n",
    "### State Space Model\n",
    "\n",
    "$$x_+ = Ax + Bu$$\n",
    "\n",
    "\n",
    "### Cost function \n",
    "\n",
    "$$\\phi(x,u) = | x- {x^*} |_p$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important for Pratham (change to linear dynamic model approximation to CSTR)\n",
    "class ModelIntegration:\n",
    "    '''\n",
    "    This files integrates the model.\n",
    "    model: this is where the model should be changed\n",
    "    '''\n",
    "\n",
    "    # --- initializing model --- #\n",
    "    def __init__(self, parameters):\n",
    "\n",
    "        # Object variable definitions\n",
    "        self.parameters = parameters\n",
    "\n",
    "\n",
    "    # --- dynamic model definition --- #\n",
    "    def model(self, t, state, u):\n",
    "        # internal definitions\n",
    "        params = self.parameters\n",
    "        x      = state\n",
    "\n",
    "        # parameters\n",
    "        A  = params[0]; B  = params[1];\n",
    "\n",
    "        # state update equations\n",
    "        dx = A*x + B*u\n",
    "\n",
    "        return dx[0] \n",
    "\n",
    "    # --- simulation --- #\n",
    "    def simulation(self, controls, x0):\n",
    "        '''\n",
    "        u shape -> (u_{dim},steps)\n",
    "        '''\n",
    "\n",
    "        # external definitions\n",
    "        self.x0 = x0\n",
    "\n",
    "        # internal definitions\n",
    "        steps = controls.shape[0]\n",
    "\n",
    "        # compile state trajectories\n",
    "        xt = np.zeros((x0.shape[0],steps+1))\n",
    "        tt = np.zeros((steps+1))\n",
    "\n",
    "        # initialize simulation\n",
    "        current_state = x0\n",
    "        xt[:,0]       = current_state\n",
    "        tt[0]         = 0.\n",
    "\n",
    "        # simulation\n",
    "        for s in range(steps):\n",
    "            u    = controls[s]\n",
    "            current_state = self.model(s, current_state, u)\n",
    "            xt[:,s+1]     = np.array(current_state).reshape(1,1)   \n",
    "            tt[s+1]       = (s+1)*1\n",
    "\n",
    "        return xt[:,-1], tt[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Functions, $\\pi$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions to be used for projection to control space\n",
    "\n",
    "def control_proj(y, control_ub=20, control_lb=-20):\n",
    "  return torch.tensor(control_ub - control_lb) * y + torch.tensor(control_lb)\n",
    "\n",
    "\n",
    "def mean_std(m, mean_ub=[10,10,10], mean_lb=[0, 0, 0]):\n",
    "    '''\n",
    "    Problem specific restrinctions on prediction via upper and lower bound on PID gains\n",
    "    '''\n",
    "\n",
    "    mean = (torch.tensor(mean_ub) - torch.tensor(mean_lb)) * m + torch.tensor(mean_lb)\n",
    "\n",
    "\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PIDController:\n",
    "    \"\"\"\n",
    "    A Proportional-Integral-Derivative (PID) controller.\n",
    "\n",
    "    Attributes:\n",
    "        kp (float): Proportional gain.\n",
    "        ki (float): Integral gain.\n",
    "        kd (float): Derivative gain.\n",
    "        setpoint (float): Desired target value.\n",
    "        integral (float): Accumulated integral of the error.\n",
    "        previous_error (float): Error from the previous step.\n",
    "        output_limits (tuple): Minimum and maximum limits for the controller output.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dt, setpoint=0.0, output_limits=(None, None)):\n",
    "        \"\"\"\n",
    "        Initializes the PID controller with given parameters.\n",
    "\n",
    "        Args:\n",
    "            kp (float): Proportional gain.\n",
    "            ki (float): Integral gain.\n",
    "            kd (float): Derivative gain.\n",
    "            setpoint (float, optional): Desired target value. Defaults to 0.0.\n",
    "            output_limits (tuple, optional): Tuple of (min_output, max_output). Defaults to (None, None).\n",
    "        \"\"\"\n",
    "\n",
    "        self.setpoint = setpoint\n",
    "\n",
    "        self.integral = 0.0\n",
    "        self.previous_error = 0.0\n",
    "        self.dt = dt\n",
    "        self.output_limits = output_limits\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the PID controller state.\n",
    "        \"\"\"\n",
    "        self.integral = 0.0\n",
    "        self.previous_error = 0.0\n",
    "\n",
    "    def compute(self, PID_params, current_value):\n",
    "        \"\"\"\n",
    "        Computes the PID control output.\n",
    "\n",
    "        Args:\n",
    "            current_value (float): The current measured value.\n",
    "            dt (float): Time interval since the last update (in seconds).\n",
    "\n",
    "        Returns:\n",
    "            float: Control output.\n",
    "        \"\"\"\n",
    "        dt = self.dt\n",
    "        setpoint = self.setpoint\n",
    "\n",
    "        kp, ki, kd = PID_params[0,0], PID_params[0,1], PID_params[0,2]\n",
    "\n",
    "\n",
    "        # Calculate error\n",
    "        error = setpoint - current_value\n",
    "\n",
    "        # Proportional term\n",
    "        p = kp * error\n",
    "\n",
    "        # Integral term with anti-windup via clamping\n",
    "        self.integral += error * dt\n",
    "        i = ki * self.integral\n",
    "\n",
    "        # Derivative term\n",
    "        derivative = (error - self.previous_error) / dt\n",
    "        d = kd * derivative\n",
    "\n",
    "        # Compute the output\n",
    "        output = p + i + d\n",
    "\n",
    "        # Apply output limits\n",
    "        min_output, max_output = self.output_limits\n",
    "        if min_output is not None:\n",
    "            output = max(min_output, output)\n",
    "        if max_output is not None:\n",
    "            output = min(max_output, output)\n",
    "\n",
    "        # Save error for next derivative calculation\n",
    "        self.previous_error = error\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Neural Networks --- #\n",
    "class Net(torch.nn.Module):\n",
    "  def __init__(self, **kwargs):\n",
    "    super(Net, self).__init__()\n",
    "    # This structure is used to define th hybrid policy model\n",
    "\n",
    "    # Unpack the dictionary\n",
    "    self.args     = kwargs\n",
    "    self.dtype    = torch.float\n",
    "    self.use_cuda = torch.cuda.is_available()\n",
    "    self.device   = torch.device(\"cpu\")\n",
    "    self.PID_controller = PIDController(self.args['dt'])\n",
    "\n",
    "    # defining ANN topology\n",
    "    self.input_size = self.args['input_size']\n",
    "    self.hs1        = self.args['hs1']\n",
    "    self.hs2        = self.args['hs2']\n",
    "    self.output_sz  = self.args['output_size']\n",
    "\n",
    "    # defining activation functions\n",
    "    self.tanh   = torch.nn.Tanh()\n",
    "\n",
    "    # connect the layers\n",
    "    self.hidden1 = torch.nn.RNN(self.input_size, self.hs1)\n",
    "    self.hidden2 = torch.nn.Linear(self.hs1, self.hs2)\n",
    "\n",
    "    # defining output layer\n",
    "    self.output = torch.nn.Linear(self.hs2, self.output_sz)\n",
    "    self.reset_hn()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x           = torch.tensor(x.view(1,1,-1)).float() # standardized input\n",
    "    a1, self.hn = self.hidden1(x, self.hn)\n",
    "    a2          = self.tanh(self.hidden2(a1))\n",
    "    y           = (self.tanh(self.output(a2))+1)/2\n",
    "\n",
    "    y = mean_std(y)\n",
    "\n",
    "    control = self.PID_controller.compute(y.reshape(1,-1), x)\n",
    "    return control.detach().numpy().squeeze().reshape(1,1)\n",
    "\n",
    "  def reset_hn(self):\n",
    "    self.hn = None\n",
    "    return\n",
    "\n",
    "class Net2(torch.nn.Module):\n",
    "  def __init__(self, **kwargs):\n",
    "    super(Net2, self).__init__()\n",
    "    # This structure is used to define th NN only policy model\n",
    "    # Unpack the dictionary\n",
    "    self.args     = kwargs\n",
    "    self.dtype    = torch.float\n",
    "    self.use_cuda = torch.cuda.is_available()\n",
    "    self.device   = torch.device(\"cpu\")\n",
    "    self.PID_controller = PIDController(self.args['dt'])\n",
    "\n",
    "    # defining ANN topology\n",
    "    self.input_size = self.args['input_size']\n",
    "    self.hs1        = self.args['hs1']\n",
    "    self.hs2        = self.args['hs2']\n",
    "    self.output_sz  = self.args['output_size']\n",
    "\n",
    "    # defining activation functions\n",
    "    self.tanh   = torch.nn.Tanh()\n",
    "\n",
    "    # connect the layers\n",
    "    self.hidden1 = torch.nn.RNN(self.input_size, self.hs1)\n",
    "    self.hidden2 = torch.nn.Linear(self.hs1, self.hs2)\n",
    "\n",
    "    # defining output layer\n",
    "    self.output = torch.nn.Linear(self.hs2, self.output_sz)\n",
    "    self.reset_hn()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x           = torch.tensor(x.view(1,1,-1)).float() # standardized input\n",
    "    a1, self.hn = self.hidden1(x, self.hn)\n",
    "    a2          = self.tanh(self.hidden2(a1))\n",
    "    y           = (self.tanh(self.output(a2))+1)/2\n",
    "\n",
    "    y = control_proj(y)\n",
    "\n",
    "    return y.detach().numpy().squeeze().reshape(1,1)\n",
    "\n",
    "  def reset_hn(self):\n",
    "    self.hn = None\n",
    "    return\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **General Algorithm: PSO**\n",
    "```\n",
    "for each particle i = 1, ..., S do:\n",
    "```\n",
    "```\n",
    "    Initialize the particle's position with a uniformly distributed random vector: xi ~ U(blo, bup)\n",
    "    Initialize the particle's best known position to its initial position: pi ← xi\n",
    "    if f(pi) < f(g) then\n",
    "        update the swarm's best known position: g ← pi\n",
    "    Initialize the particle's velocity: vi ~ U(-|bup-blo|, |bup-blo|)\n",
    "```\n",
    "```\n",
    "while a termination criterion is not met do:\n",
    "```\n",
    "```\n",
    "    for each particle i = 1, ..., S do\n",
    "        for each dimension d = 1, ..., n do\n",
    "            Pick random numbers: rp, rg ~ U(0,1)\n",
    "            Update the particle's velocity: vi,d ← ω vi,d + φp rp (pi,d-xi,d) + φg rg (gd-xi,d)\n",
    "        Update the particle's position: xi ← xi + lr vi\n",
    "        if f(xi) < f(pi) then\n",
    "            Update the particle's best known position: pi ← xi\n",
    "            if f(pi) < f(g) then\n",
    "                Update the swarm's best known position: g ← pi\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# ------- Particle Swarm Optimisation Functions ------- #\n",
    "#########################################################\n",
    "\n",
    "# ------------------------------------------------------- #\n",
    "# -------------- Method Specific functions -------------- #\n",
    "# ------------------------------------------------------- #\n",
    "\n",
    "\n",
    "def local_best_get(particle_pos,particle_pos_val,p):\n",
    "    local_best=[0]*p #creating empty local best list\n",
    "    for j in range(p):  #finding the best particle in each neighbourhood\n",
    "                        #and storing it in 'local_best'\n",
    "        local_vals=np.zeros(3)\n",
    "        local_vals[0]=particle_pos_val[j-2]\n",
    "        local_vals[1]=particle_pos_val[j-1]\n",
    "        local_vals[2]=particle_pos_val[j]\n",
    "        min_index=int(np.argmin(local_vals))\n",
    "        local_best[j-1]=particle_pos[min_index+j-2][:]\n",
    "    return np.array(local_best)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def PSUinitiation(f,bounds,p):\n",
    "    '''\n",
    "    INPUTS\n",
    "    f       :function to be searched over\n",
    "    bounds  :bounds of function in form [[x1,x2],[x3,x4],[x5,x6]...]\n",
    "    p       :number of particles\n",
    "\n",
    "    OUTPUTS\n",
    "    particle_pos      :array of random particle positions\n",
    "    particle_best     :array of best particle positions (same as current)\n",
    "    swarm_best        :coordinates of particle with best known position\n",
    "    particle_velocity :array of random particle velocity arrays\n",
    "    local_best        :array of the best particle in each neighbourhood\n",
    "    local_best_fitness:function value evaluated at each local best\n",
    "    particle_pos_val  :fitness of each particle\n",
    "\n",
    "    '''\n",
    "    d=len(bounds) #finding number of dimensions\n",
    "    particle_pos=np.zeros(p) #creating empty position array\n",
    "    particle_pos=particle_pos.tolist() #converting array to list\n",
    "    particle_velocity=particle_pos[:] #empty velocity array\n",
    "    particle_pos_val=particle_pos[:] #empty value array\n",
    "    for j in range(p): #iterating ovre the number of particles\n",
    "        particle_pos[j]=[rnd.uniform(bounds[i][0],bounds[i][1])\\\n",
    "                    for i in range(d)] #random coordinate within bounds\n",
    "        particle_pos_val[j]=f(particle_pos[j]) #calculating function value\n",
    "                                            #at each particle\n",
    "        particle_velocity[j]=[rnd.uniform(-abs(bounds[i][1]-bounds[i][0])\\\n",
    "                    ,abs(bounds[i][1]-bounds[i][0])) for i in range(d)]\n",
    "                    #creating random velocity values for each dimension\n",
    "\n",
    "    local_best=local_best_get(particle_pos,particle_pos_val,p)\n",
    "\n",
    "    swarm_best=particle_pos[np.argmin(particle_pos_val)]#getting the lowest particle value\n",
    "    particle_best=copy.deepcopy(particle_pos)#setting all particles current positions to best\n",
    "    return d,np.array(particle_pos), np.array(particle_best), \\\n",
    "                 np.array(swarm_best), np.array(particle_velocity), np.array(local_best), \\\n",
    "                     np.array(particle_pos_val)\n",
    "\n",
    "def PSUwithinbounds(bounds,particle_pos):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        Checks whether a particle's position is within the bounds of the problem\n",
    "        and contraints particles within bounds\n",
    "\n",
    "    INPUTS\n",
    "    bounds      :bounds of problem in form [[x1,x2],[x3,x4]...]\n",
    "    particle_pos:coordinates of a particle e.g [p1,p2,p3...]\n",
    "\n",
    "\n",
    "    '''\n",
    "    for i in range(len(bounds)):\n",
    "        if particle_pos[i]<bounds[i][0]: #if particle is less than lower bound\n",
    "            particle_pos[i]=bounds[i][0]\n",
    "        elif particle_pos[i]>bounds[i][1]: #if particle is more than higher bound\n",
    "            particle_pos[i]=bounds[i][1]\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def particleswarm(f,bounds,p,c1,c2,vmax,tol):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "    see https://en.wikipedia.org/wiki/Particle_swarm_optimization\n",
    "\n",
    "    INPUTS\n",
    "    f           :function to be optimized\n",
    "    bounds      :bounds of each dimension in form [[x1,x2],[x3,x4]...]\n",
    "    p           :number of particles\n",
    "    c1          :adjustable parameter\n",
    "    c2          :adjustable parameter\n",
    "    vmax        :maximum particle velocity\n",
    "    tol         :tolerance for exit condition\n",
    "\n",
    "    OUTPUTS\n",
    "    swarm_best  : coordinates of optimal solution, with regards to exit\n",
    "                  conditions\n",
    "    '''\n",
    "    print('Currently placing particles and giving them random \\\n",
    "    velocities...')\n",
    "    d,particle_pos, particle_best, swarm_best, particle_velocity, \\\n",
    "        local_best, pos_val \\\n",
    "    = PSUinitiation(f,bounds,p) #initializing various arrays\n",
    "    old_swarm_best=[0]*d\n",
    "    c3=c1+c2\n",
    "    K=2/(abs(2-c3-np.sqrt((c3**2)-(4*c3)))) #creating velocity weighting factor\n",
    "    it_count=0\n",
    "    while (abs(f(old_swarm_best)-f(swarm_best))>tol) & (it_count < 300): #exit condition\n",
    "\n",
    "        it_count+=1\n",
    "        if it_count>1000: #every 1000 iterations...\n",
    "                        #create 'conflict' within the swarm and\n",
    "                        #give all particles random velocities\n",
    "            print('Particles are too friendly! Creating conflict...')\n",
    "            for j in range(p): #iterating ovre the number of particles\n",
    "                particle_velocity[j]=[(rnd.uniform(-abs(bounds[i][1]-bounds[i][0])\\\n",
    "                    ,abs(bounds[i][1]-bounds[i][0]))) for i in range(d)]\n",
    "                    #adding random velocity values for each dimension\n",
    "            it_count=0 #reset iteration count\n",
    "\n",
    "        for i in range(p): #iterates over each particle\n",
    "            rp,rg=rnd.uniform(0,1,2) #creates two random numbers between 0-\n",
    "            particle_velocity[i,:]+=(c1*rp*(particle_best[i,:]-particle_pos[i,:]))\n",
    "            particle_velocity[i,:]+=(c2*rg*(local_best[i,:]-particle_pos[i,:]))\n",
    "            particle_velocity[i,:]=particle_velocity[i,:]*K\n",
    "            if particle_velocity[i].any() > vmax : #is any velocity is greater than vmax\n",
    "                    particle_velocity[i,:]=vmax #set velocity to vmax\n",
    "            #all of the above is regarding updating the particle's velocity\n",
    "            #with regards to various parameters (local_best, p_best etc..)\n",
    "            particle_pos[i,:]+=particle_velocity[i,:] #updating position\n",
    "\n",
    "            PSUwithinbounds(bounds,particle_pos[i]) #if particle is out of bounds\n",
    "\n",
    "            particle_fitness=f(particle_pos[i])\n",
    "\n",
    "            if particle_fitness < pos_val[i]:\n",
    "                particle_best[i,:]=particle_pos[i,:] #checking if new best\n",
    "                pos_val[i]=particle_fitness\n",
    "                f_swarm_best=f(swarm_best)\n",
    "                if particle_fitness < f_swarm_best:\n",
    "                    old_swarm_best=swarm_best[:]\n",
    "                    swarm_best=copy.deepcopy(particle_best[i,:])\n",
    "                    #print('current function value: ',f(swarm_best))\n",
    "\n",
    "        local_best=local_best_get(particle_pos,pos_val,p)\n",
    "\n",
    "    print('PSO Optimum at: ',swarm_best,'\\n','Function at optimum: ',f(swarm_best), '\\n', 'function evals:', it_count*p)\n",
    "    return swarm_best, f(swarm_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# one episode run function #\n",
    "############################\n",
    "\n",
    "class Simulation(object):\n",
    "  def __init__(self, sample_size, nk, nu, nx, x0, x0_var, theta,\n",
    "                    theta_var, u_min, u_max, x_mean, x_std, l2_regc, network, **kwargs):\n",
    "    # --- unpacking arguments --- #\n",
    "    self.sample_size = sample_size\n",
    "    self.nk, self.nu, self.nx, self.x0, self.x0_var = nk, nu, nx, x0, x0_var\n",
    "    self.theta, self.theta_var, self.l2_regc = theta, theta_var, l2_regc\n",
    "    self.u_min, self.u_max, self.x_mean, self.x_std = u_min, u_max, x_mean, x_std\n",
    "    self.policy = network(**kwargs)\n",
    "\n",
    "\n",
    "  def run_episode(self, policy1, x0, model):\n",
    "      '''\n",
    "      This code is adapted for the optimization of a batch process, meaning a fixed final\n",
    "      time, and a state as \"time-to-termination\"\n",
    "\n",
    "      Single MC: Compute a single episode given a policy.\n",
    "      input: Specification\n",
    "      Output: Reward for each episode\n",
    "\n",
    "      nk: number of steps, dis:, F, x0: initial state, u_min, u_max\n",
    "      '''\n",
    "      # --- unpacking arguments --- #\n",
    "      nk, nu, nx, x0 = self.nk, self.nu, self.nx, self.x0\n",
    "      u_min, u_max, x_std = self.u_min, self.u_max, self.x_std\n",
    "\n",
    "\n",
    "      # ----------- Initialize episode ----------- #\n",
    "      u_trajectory = np.zeros([nk, nu]) #U = np.zeros([nk, nu]) erase\n",
    "      x_trajectory = np.zeros([nk, nx]) #y = np.zeros([nk, nx]) erase\n",
    "\n",
    "      # -- initial conditions -- #\n",
    "      x_k = x0.copy() # integrated_staten = x0.copy()\n",
    "\n",
    "      # ---- Perform MC for each time interval of (nk) steps ---- #\n",
    "      for ind in range(nk):\n",
    "\n",
    "          # ----- normalizing inputs ----- #\n",
    "          x_k_norm = (x_k - x_mean)/x_std\n",
    "          # ----- Compute next control action ----- #\n",
    "          x_k_norm_torch          = torch.tensor((x_k_norm))\n",
    "          #print(policy1(x_k_norm_torch).shape )\n",
    "          mean_uk                 = policy1(x_k_norm_torch)   # control prediction from PID\n",
    "          #print(mean_uk, mean_uk.shape)\n",
    "          u_k                     = np.reshape(mean_uk, (nu, 1))\n",
    "          # ----- hard bounds on constraints ----- #\n",
    "          for i_u in range(len(u_min)): # enforcing bounds on the control prediction\n",
    "              if u_k[i_u]  < u_min[i_u]:\n",
    "                  u_k[i_u] = u_min[i_u]\n",
    "              if u_k[i_u]  > u_max[i_u]:\n",
    "                  u_k[i_u] = u_max[i_u]\n",
    "\n",
    "          # ----- compute next states from \"real system\" ----- #\n",
    "          xt, _ = model.simulation(np.array(u_k).reshape(1,-1), x_k) # system simulation of continuous time dynamics and next observation of systems state\n",
    "          x_k = xt\n",
    "          # ----- storage of data ----- #\n",
    "          u_trajectory[ind, :] = np.copy(np.array(u_k).reshape(1,-1))\n",
    "          #print(x_k)\n",
    "          x_trajectory[ind, :] = np.copy(np.array(x_k).reshape(1,-1))\n",
    "\n",
    "\n",
    "\n",
    "      # ----- return ----- #\n",
    "      return  u_trajectory, x_trajectory\n",
    "\n",
    "  ############################\n",
    "  # Sample episodes function #\n",
    "  ############################\n",
    "\n",
    "  def load_params(self, x):\n",
    "    # --- unpacking arguments --- #\n",
    "    policy = self.policy\n",
    "\n",
    "    layers = [xt1.data for xt1 in policy.parameters()]\n",
    "    indx_l = np.array(0)\n",
    "    indx   = np.array(0)\n",
    "    for i in range(len(layers)):\n",
    "      try:\n",
    "        dim = layers[i].data.shape[0] * layers[i].data.shape[1]\n",
    "      except:\n",
    "        dim = layers[i].data.shape[0]\n",
    "\n",
    "      # transfer x value to parameters of neural network\n",
    "      indx += np.array(dim)\n",
    "      layers[i].data.copy_(torch.tensor(x[indx_l:indx]).reshape(layers[i].data.shape))\n",
    "      indx_l = indx.copy()\n",
    "\n",
    "    self.policy = policy\n",
    "\n",
    "    return self.policy\n",
    "\n",
    "  def RL_simulation(self,x, validate = False):\n",
    "      '''\n",
    "      Perform all the MC's for a given candidate. This means we either evaluate the candidate once\n",
    "      in the case of a deterministic system and 50+ evaluations for stochastic systems.\n",
    "\n",
    "      input: Policy, physical system, specifications\n",
    "      output: expected reward, historical data\n",
    "      '''\n",
    "      # --- unpacking arguments --- #\n",
    "      nk, nu, nx, x0, x0_var = self.nk, self.nu, self.nx, self.x0, self.x0_var\n",
    "      theta, theta_var = self.theta, self.theta_var\n",
    "      sample_size = self.sample_size\n",
    "      # ----- internal definitions ----- #\n",
    "      rewards          = [None for _ in range(sample_size)]\n",
    "\n",
    "      # historical data\n",
    "      h_xs = np.zeros([sample_size, nk+1, nx])\n",
    "      h_us = np.zeros([sample_size, nk, nu])\n",
    "\n",
    "      # load parameters of current sample\n",
    "      policy1 = self.load_params(x)\n",
    "\n",
    "\n",
    "      # ----- loop over a number of episodes ----- #\n",
    "      for epi in range(sample_size):\n",
    "\n",
    "          # Parametric uncertainty\n",
    "          pvar_epi     = np.random.multivariate_normal(np.zeros(theta_var.shape[0]), np.diagflat(theta_var))\n",
    "          theta_epi    = {indx:theta[indx]+pvar_epi[indx] for indx,key1 in enumerate(theta)}\n",
    "          model        = ModelIntegration(theta_epi)\n",
    "          # Random intial conditions\n",
    "          x0_epi       = x0 + np.random.multivariate_normal(np.zeros(nx), np.diagflat(x0_var))\n",
    "\n",
    "          # ----- Historical data ----- #\n",
    "          h_xs[epi, 0, :]       = x0_epi\n",
    "          u_trajectory, x_trajectory = \\\n",
    "          self.run_episode(policy1, x0_epi, model)\n",
    "          h_xs[epi, 1:, :]      = x_trajectory\n",
    "          h_us[epi, :, :]       = u_trajectory\n",
    "\n",
    "\n",
    "      # ----- Return ----- #\n",
    "      if validate:\n",
    "        return  h_us, h_xs, np.sum(np.sum(np.abs(x_trajectory), axis=0), axis=0)\n",
    "      else: return np.sum(np.sum(np.abs(x_trajectory), axis=0), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define policy function to optimise weights of\n",
    "hypparams = {'input_size': 1,\n",
    "          'hs1': 10,\n",
    "          'hs2': 1,\n",
    "          'output_size': 3,\n",
    "             'dt': 1}\n",
    "\n",
    "hypparams2 = {'input_size': 1,\n",
    "          'hs1': 10,\n",
    "          'hs2': 5,\n",
    "          'output_size': 1,\n",
    "             'dt': 1}\n",
    "\n",
    "Qnet = Net(**hypparams)\n",
    "piNet = Net2(**hypparams2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find dimensionality of the optimisation problem\n",
    "# this will not work for convolutional layers\n",
    "dim_ =[]\n",
    "for p in [Qnet, piNet]:\n",
    "  params = list(p.parameters())\n",
    "  dim = 0\n",
    "  for p in params:\n",
    "    try:\n",
    "      dim += p.shape[0] * p.shape[1]\n",
    "    except:\n",
    "      dim += p.shape[0]\n",
    "\n",
    "  dim_.append(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently placing particles and giving them random     velocities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6071/3759933874.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x           = torch.tensor(x.view(1,1,-1)).float() # standardized input\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSO Optimum at:  [-4.50427792  5.          5.         -5.         -5.         -4.84706433\n",
      "  5.         -5.          5.         -5.          5.          0.40851752\n",
      " -5.          0.57766924  5.         -2.7655259  -5.          5.\n",
      " -5.          5.         -5.          5.         -5.          5.\n",
      " -0.91217292  5.          5.          5.         -5.         -3.01287534\n",
      " -5.         -5.         -5.          4.65985977 -4.98243244 -5.\n",
      " -5.          5.          3.94276318 -5.          4.91631444  2.79108359\n",
      "  5.         -5.         -5.         -5.         -3.48939504 -5.\n",
      " -5.         -5.         -5.          5.          5.          3.24298987\n",
      " -5.         -5.         -1.79170191 -4.70979785 -5.          5.\n",
      " -5.          5.         -5.          5.          5.         -5.\n",
      "  5.         -2.92552198  5.         -5.         -4.66788077  4.61739422\n",
      " -5.          1.8399647   5.          5.         -5.         -5.\n",
      "  4.32126559  3.96830555  5.         -5.          5.          5.\n",
      " -5.         -5.         -5.         -3.8530665  -5.          3.23957684\n",
      " -3.8552641   1.10670603 -3.87550189 -5.         -5.          5.\n",
      " -5.         -5.          5.         -5.          2.26318293 -5.\n",
      "  5.          4.50787422  5.          4.45844369  5.         -4.78069702\n",
      "  4.50202088  5.         -5.          1.40950307 -4.67341366  5.\n",
      "  5.          5.          4.37786872  4.71462657  5.         -3.24157203\n",
      " -4.7631491  -4.54057389 -0.94165125 -5.         -5.         -4.43801218\n",
      "  5.          5.         -5.          5.         -5.          5.\n",
      " -5.         -5.          5.          5.          4.67972353 -5.\n",
      "  5.          5.          5.          5.         -4.75129225 -5.\n",
      "  5.         -5.         -5.        ] \n",
      " Function at optimum:  5.333333333333333 \n",
      " function evals: 1500\n",
      "Currently placing particles and giving them random     velocities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6071/3759933874.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x           = torch.tensor(x.view(1,1,-1)).float() # standardized input\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSO Optimum at:  [ 0.00683496 -5.         -5.         -4.0152318  -5.         -5.\n",
      "  1.36105448 -5.         -1.6727909  -4.39686944 -5.          4.12468453\n",
      "  3.95885482 -3.64347639  3.03038411 -5.         -3.35577781 -0.36641418\n",
      "  2.60432513 -1.97798136  4.50270194  2.5564176  -4.72387844  0.44196525\n",
      " -3.1008072   3.89189525 -4.16832542 -5.         -4.22397152 -4.32877224\n",
      "  5.         -2.75543723 -3.20568608 -1.32593918  5.          1.99799381\n",
      " -5.         -5.         -5.          5.         -2.62275406  0.14679128\n",
      "  5.          5.          5.         -4.48129021 -0.60818689 -4.44753195\n",
      " -2.4882998   5.         -2.80346633 -5.          1.62253747 -1.67517978\n",
      "  5.         -0.09241934 -0.66845008 -1.11696044  5.         -3.82097089\n",
      " -3.47466744 -5.          2.37845792  5.         -0.26040303 -4.77324201\n",
      " -3.39641317  2.0921066  -5.         -4.04104164 -5.         -0.80079778\n",
      " -5.          4.34316615  0.45077366 -3.71744271  4.98475841  5.\n",
      "  4.47973973 -2.04102486  5.          1.08257046  4.98900239 -0.66598594\n",
      "  5.         -1.14478172  5.          5.         -1.51164056  0.86745245\n",
      " -3.30607127  1.11645064 -5.         -0.95095345 -0.18738615 -5.\n",
      " -5.         -4.9429354   1.93852128  1.01174856 -5.          1.09144618\n",
      "  5.          3.51296402 -1.06702094  5.         -5.          5.\n",
      " -4.37042971 -4.28671251  3.58071274 -5.         -4.6024552   5.\n",
      " -5.         -0.23109765  5.         -3.95923573 -0.67635724  5.\n",
      "  5.          5.         -1.98042385 -5.          5.         -5.\n",
      " -5.         -5.          2.32448459 -5.          4.49504819 -5.\n",
      " -4.45357179 -0.63716648 -5.          5.          5.          1.76342134\n",
      "  5.          0.95259096  0.50101605 -2.37899225  3.67448261  5.\n",
      " -0.23715851 -3.72699821  5.         -5.          5.          3.2409439\n",
      "  4.62423855  5.         -5.          4.24745396  5.         -3.90000024\n",
      "  3.71289595 -5.          4.96760578  4.39907886  5.          4.91171982\n",
      "  2.9738742  -0.22568374  5.         -4.93604091  5.         -3.21746638\n",
      "  5.          5.         -4.27087812 -5.         -3.44025098  5.\n",
      "  3.51948506 -0.41436021 -3.90747703  3.21216397  2.22439219 -5.\n",
      "  4.66403903 -5.         -3.01181957 -5.          5.         -2.36791564\n",
      " -5.          2.4068178   5.          4.17354383 -2.615279  ] \n",
      " Function at optimum:  5.950526809692369 \n",
      " function evals: 18000\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "hypp = [hypparams, hypparams2]\n",
    "# ---------- set random seed and timers ---------- #\n",
    "torch.manual_seed(666)\n",
    "now = datetime.datetime.now()\n",
    "np.random.seed(seed=0)\n",
    "\n",
    "# ---------- problem definition ---------- #\n",
    "p        = {'u_m' : 1, 'K_N' : 0.3, 'u_d' : 0.01, 'Y_nx' : 504.49}                 # model parameter definitions\n",
    "nx                 = 1\n",
    "nu                 = 1\n",
    "epochs             = 500\n",
    "episodes           = 1\n",
    "nk                 = 30\n",
    "x_mean             = np.array([0])\n",
    "x_std              = np.array([4.])\n",
    "u_max              = np.array([20.])\n",
    "u_min              = np.array([-20.])\n",
    "u_mean             = (u_max + u_min)/2.\n",
    "u_std              = (u_max - u_min)/2.\n",
    "x0                 = np.array([10])\n",
    "x0_var             = np.sqrt(x0)*1e-12\n",
    "theta_var          = np.array([p[key]*0 for key in p])      # currently a deterministic system\n",
    "theta              = np.array([p[key] for key in p])\n",
    "l2_regc            = 1e-12\n",
    "\n",
    "controls, states, obj = {k: {i: None for i in range(5)} for k in range(2)}, {k: {i: None for i in range(5)} for k in range(2)}, {k: {i: None for i in range(5)} for k in range(2)}\n",
    "\n",
    "for k in range(1):\n",
    "\n",
    "  for j, (hp, dim, network) in enumerate(zip(hypp, dim_, [Net, Net2])):\n",
    "\n",
    "    f = Simulation(episodes, nk, nu, nx, x0, x0_var, theta,\n",
    "                        theta_var, u_min, u_max, x_mean, x_std, l2_regc, network, **hp)\n",
    "\n",
    "    dimensions=dim\n",
    "    dimension_bounds=[-5,5]   # bounds are important here\n",
    "    bounds=[0]*dimensions     #creating n_d dimensional bounds\n",
    "    for i in range(dimensions):\n",
    "        bounds[i]=dimension_bounds\n",
    "\n",
    "    #creates bounds [[x1,x2],[x3,x4],[x5,x6]....]\n",
    "\n",
    "    # --- metrics for pso --- #\n",
    "    p=60 #shouldn't really change\n",
    "    vmax=(dimension_bounds[1]-dimension_bounds[0])*0.75\n",
    "    c1=2.8 #shouldn't really change\n",
    "    c2=1.3 #shouldn't really change\n",
    "    tol=1e-3\n",
    "\n",
    "    # perform optimisation\n",
    "    opt_params, opt_val = particleswarm(f.RL_simulation,bounds,p,c1,c2,vmax,tol)\n",
    "\n",
    "    h_us, h_xs, objective = f.RL_simulation(opt_params, validate = True)\n",
    "\n",
    "    controls[j][k] = h_us\n",
    "    states[j][k] = h_xs\n",
    "    obj[j][k] = objective\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "font = {'family' : 'serif',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 12}\n",
    "plt.rc('font', **font)\n",
    "df = pd.DataFrame(obj).T\n",
    "df.index = ['Hybrid Policy', 'NN Policy']\n",
    "cmap_choice = 'viridis'\n",
    "\n",
    "sns.heatmap(df, annot=True, fmt=\".2f\", cmap=cmap_choice)\n",
    "#plt.title('Performance Heatmap')\n",
    "plt.xlabel('Evaluation')\n",
    "plt.ylabel('Policy structure')\n",
    "plt.savefig('Heatmap.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, (h_xs, h_us) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(states, controls)):\n\u001b[0;32m---> 10\u001b[0m   tt \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[43mh_xs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,h_xs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] )\n\u001b[1;32m     11\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(h_xs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]):\n\u001b[1;32m     12\u001b[0m       plt\u001b[38;5;241m.\u001b[39mplot(tt, h_xs[:, :, i]\u001b[38;5;241m.\u001b[39msqueeze() \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(np\u001b[38;5;241m.\u001b[39mabs(h_xs[:, :, i])), label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, $\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpi$ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-.\u001b[39m\u001b[38;5;124m'\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'shape'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "font = {'family' : 'serif',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 15}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "# Plot 1: State and Control Policy Over Time (Normalized)\n",
    "plt.figure(figsize=(10, 6))\n",
    "for k, (h_xs, h_us) in enumerate(zip(states, controls)):\n",
    "  tt = np.linspace(0, h_xs.shape[1]-1,h_xs.shape[1] )\n",
    "  for i in range(h_xs.shape[2]):\n",
    "      plt.plot(tt, h_xs[:, :, i].squeeze() / np.max(np.abs(h_xs[:, :, i])), label=f'State {i+1}, $\\pi$ {k+1}', linewidth=1.5, linestyle='-.', marker='o')\n",
    "  plt.step(tt[:-1], h_us.squeeze() / np.max(np.abs(h_us.squeeze())), where='post', label=f'Control Policy, $\\pi$ {k+1}', linestyle='--', marker='o')\n",
    "plt.ylabel('Normalized State / Control')\n",
    "plt.xlabel('Time')\n",
    "plt.title('Normalized States and Control Policy Over Time')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('state_control_normal.svg')\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Raw State Values Over Time\n",
    "plt.figure(figsize=(10, 6))\n",
    "for k, (h_xs, h_us) in enumerate(zip(states, controls)):\n",
    "  tt = np.linspace(0, h_xs.shape[1]-1,h_xs.shape[1] )\n",
    "  for i in range(h_xs.shape[2]):\n",
    "      plt.plot(tt, h_xs[0, :, i], label=f'State {i+1}, $\\pi$ {k+1}', linewidth=1.5, linestyle='-.', marker='o')\n",
    "plt.ylabel('State Value')\n",
    "plt.xlabel('Time')\n",
    "plt.title('Raw State Values Over Time')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('state_trajectory.svg')\n",
    "plt.show()\n",
    "\n",
    "# Plot 3: Control Policy Over Time\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, (h_xs, h_us) in enumerate(zip(states, controls)):\n",
    "  tt = np.linspace(0, h_xs.shape[1]-1,h_xs.shape[1] )\n",
    "  plt.step(tt[:-1], h_us[0, :, :].squeeze(), where='post', linewidth=1.5, linestyle='-.', marker='o', label=f'Control Policy, $\\pi$ {i+1}')\n",
    "plt.ylabel('Control Value')\n",
    "plt.xlabel('Time')\n",
    "plt.title('Control Policy Over Time')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('control_policy.svg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proaimxsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
